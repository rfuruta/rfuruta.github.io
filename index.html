<!DOCTYPE html>
<!-- saved from url=(0040)http://www.hal.t.u-tokyo.ac.jp/~furuta/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        
        <title>Ryosuke Furuta</title>
        <link href="./furuta_files/bootstrap.css" rel="stylesheet">
        <link href="./furuta_files/myedit.css" rel="stylesheet">
    </head>
    <body>

        <div class="container"> <!-- define by myself -->      
            <div class="text-end">
                <a href="./index_jp.html">日本語</a>/
                <a href="./index.html">English</a>
            </div>
            <br>

        <h2>Ryosuke Furuta</h2>
        <div class="row" style="margin-bottom: 20px; margin-left: 0px;">
            <div class="col-lg-2">
                <img src="photo/furuta.jpg" class="img-max-height" alt="Responsive image">
            </div>
            <div class="col-lg-10">
            <b>Research Associate (Oct. 2020 - present)</b><br>
            <a href="https://www.ut-vision.org/sato-lab/">Y. Sato Laboratory</a><br>
            Institute of Industrial Science, The University of Tokyo, Japan<br>
            E-mail: furuta (at) iis.u-tokyo.ac.jp<br><br>

            <b>Visiting Researcher (Nov. 2020 - present)</b><br>
            <a href="https://www.rs.tus.ac.jp/vml/">Taniguchi Laboratory</a><br>
            Department of Information and Computer Technology, Tokyo University of Science, Japan<br>
        </div>
        </div>

            <h3>Research Interests</h3>
            <p>Computer Vision, Image Recognition, MRF Optimization.</p>

            <h3>Work Experience</h3>
            <dl>
                <dt>Assistant Professor (Apr. 2019 - Sep. 2020)</dt>
                <dd><a href="https://www.rs.tus.ac.jp/vml/">Taniguchi Laboratory</a><br>
                Department of Information and Computer Technology, Tokyo University of Science, Japan</dd>
                
                <dt>Visiting Researcher (May 2019 - Sep. 2020)</dt>
                <dd><a href="https://www.hal.t.u-tokyo.ac.jp/lab/en?lang=en">Yamasaki Laboratory</a><br>
                Department of Information and Communication Engineering, The University of Tokyo, Japan</dd>
            </dl>

            <h3>Education</h3>
            <dl>
                <dt>Ph.D., (Apr. 2016 - Mar. 2019)</dt>
                <dd>Department of Information and Communication Engineering,<br>
                Graduate School of Information Science and Technology,<br>
                The University of Tokyo.<br>
                Advisor: <a href="http://www.hal.t.u-tokyo.ac.jp/~yamasaki/index-e.html">Prof. Toshihiko Yamasaki</a></dd>
		        <dt>M.S., (Apr. 2014 - Mar. 2016)</dt>
                <dd>Department of Information and Communication Engineering,<br>
                Graduate School of Information Science and Technology,<br>
                The University of Tokyo.<br>
                Advisor: <a href="http://www.hal.t.u-tokyo.ac.jp/~yamasaki/index-e.html">Prof. Toshihiko Yamasaki</a></dd>
                <dt>B.E., (Apr. 2010 - Mar. 2014)</dt>
                <dd>Department of Information and Communication Engineering,<br>
                The University of Tokyo.<br>
                Advisor: <a href="http://www.hal.t.u-tokyo.ac.jp/~aizawa/">Prof. Kiyoharu Aizawa</a> and <a href="http://www.hal.t.u-tokyo.ac.jp/~yamasaki/index-e.html">Prof. Toshihiko Yamasaki</a></dd>
            </dl>

            <h3 id="publications">Publications</h3>
	    <h4>Journals</h4>
            <ul>
            　<li><span class="under">Ryosuke Furuta</span>, Naoto Inoue, and Toshihiko Yamasaki<br>
                        <strong>PixelRL: Fully Convolutional Network with Multi-Step Reinforcement Learning for Image Processing</strong><br>
                        <i>IEEE TMM, 2020. (IEEE SPS Japan Young Author Best Paper Award) </i> [<a href="https://arxiv.org/abs/1912.07190">arXiv</a>] [<a href="https://ieeexplore.ieee.org/document/8936404">IEEE Xplore</a>] [<a href="./pub/fcn_rl/fcn_rl.html">project page</a>] [<a href="https://github.com/rfuruta/pixelRL">code</a>]
                    </li>
                </li>
	      　<li><span class="under">Ryosuke Furuta</span>, Naoto Inoue, and Toshihiko Yamasaki<br>
                    <strong>Efficient and Interactive Spatial-Semantic Image Retrieval</strong><br>
                    <i>MTAP, 2019.</i> [<a href="https://link.springer.com/article/10.1007/s11042-018-7148-1?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&utm_source=ArticleAuthorOnlineFirst&utm_medium=email&utm_content=AA_en_06082018&ArticleAuthorOnlineFirst_20190204">pdf (open access)</a>]
                </li>
	        <li><span class="under">Ryosuke Furuta</span>, Satoshi Ikehata, Toshihiko Yamasaki, and Kiyoharu Aizawa<br>
                    <strong>Efficiency-Enhanced Cost-Volume Filtering featuring Coarse-to-Fine Strategy</strong><br>
                    <i>MTAP, 2018.</i> [<a href="https://link.springer.com/article/10.1007/s11042-017-4897-1?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst">pdf (open access)</a>] [<a href="./pub/c2fcvf/CtF_CVF.zip">code</a>]
                </li>
                <li><span class="under">Ryosuke Furuta</span>, Ikuko Tsubaki, and Toshihiko Yamasaki<br>
                    <strong>Fast Volume Seam Carving with Multi-pass Dynamic Programming</strong><br>
                    <i>IEEE TCSVT, 2018.</i> (Telecom System Technology Award 2018) [<a href="http://ieeexplore.ieee.org/document/7755760/">pdf (open access)</a>] [<a href="./pub/vsc/result.mp4">video</a>] [<a href="./pub/vsc/suppl.pdf">supplementary</a>]
                </li>
	    </ul>
            <h4>International conferences</h4>
            <ul>
            <li>Xinyun Li, <span class="under">Ryosuke Furuta</span>, Go Irie, and Yukinobu Taniguchi<br>
                    <strong>Accurate Indoor Localization using Multi-view Image Distance</strong><br>
                    <i>IEVC, 2021.</i>
                </li>
            <li>Risako Ii, <span class="under">Ryosuke Furuta</span>, and Yukinobu Taniguchi<br>
                    <strong>Distortion Correction and Stitching of Overlapping Cattle Barn Images</strong><br>
                    <i>IEVC, 2021.</i>
                </li>
            <li>Yugo Shimizu, <span class="under">Ryosuke Furuta</span>, Delong Ouyang, Yukinobu Taniguchi, Ryota Hinami, and Shonosuke Ishiwatari<br>
                    <strong>Painting Style-Aware Manga Colorization Based on Generative Adversarial Networks</strong><br>
                    <i>ICIP, 2021.</i> [<a href="https://arxiv.org/abs/2107.07943">arXiv</a>]
                </li>
            <li>Shunta Komatsu, <span class="under">Ryosuke Furuta</span>, and Yukinobu Taniguchi<br>
                    <strong>Passenger Flow Estimation with Bipartite Matching on Bus Surveillance Cameras</strong><br>
                    <i>MIPR, 2021.</i>
                </li>
        　  <li>Masaki Sugimoto, <span class="under">Ryosuke Furuta</span>, and Yukinobu Taniguchi<br>
                    <strong>Weakly-Supervised Human-Object Interaction Detection</strong><br>
                    <i>VISAPP, 2021.</i>
                </li>
        　  <li><span class="under">Ryosuke Furuta</span>, Naoaki Noguchi, Xueting Wang, and Toshihiko Yamasaki<br>
                    <strong>Feature Point Matching in Cross-Spectral Images with Cycle Consistency Learning</strong><br>
                    <i>ICPR, 2020.</i>
                </li>
	        <li><span class="under">Ryosuke Furuta</span>, Naoto Inoue, and Toshihiko Yamasaki<br>
                    <strong>Fully Convolutional Network with Multi-Step Reinforcement Learning for Image Processing</strong><br>
                    <i>AAAI, 2019.</i> (acceptance rate 16.2%) [<a href="https://arxiv.org/abs/1811.04323">arXiv</a>] [<a href="https://aaai.org/ojs/index.php/AAAI/article/view/4240">proceedings</a>] [<a href="./pub/fcn_rl/fcn_rl.html">project page</a>] [<a href="https://github.com/rfuruta/pixelRL">code</a>]
                </li>
	      　<li>Naoto Inoue, <span class="under">Ryosuke Furuta</span>, Toshihiko Yamasaki, and Kiyoharu Aizawa<br>
                    <strong>Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation</strong><br>
                    <i>IEEE CVPR, 2018.</i> (acceptance rate 29.1%) [<a href="https://arxiv.org/abs/1803.11365">pdf</a>] [<a href="https://naoto0804.github.io/cross_domain_detection/">project page</a>] [<a href="https://github.com/naoto0804/cross-domain-detection">code</a>]
               </li>
	      　<li><span class="under">Ryosuke Furuta</span>, Naoto Inoue, and Toshihiko Yamasaki<br>
                    <strong>Efficient and Interactive Spatial-Semantic Image Retrieval</strong><br>
                    <i>MMM, 2018.</i> [<a href="./pub/retrieval/llncs.pdf">pdf</a>]
                </li>
	      	<li>Sijie Shen, <span class="under">Ryosuke Furuta</span>, Toshihiko Yamasaki and Kiyoharu Aizawa<br>
                    <strong>Fooling Neural Networks in Face Attractiveness Evaluation: Adversarial Examples with High Attractiveness Score but Low Subjective Score</strong><br>
                    <i>IEEE BigMM (short paper), 2017.</i>
		</li>
	      	<li>Naoto Inoue, <span class="under">Ryosuke Furuta</span>, Toshihiko Yamasaki and Kiyoharu Aizawa<br>
                    <strong>Object Detection Refinement Using Markov Random Field Based Pruning and Learning Based Rescoring</strong><br>
                    <i>IEEE ICASSP, 2017.</i> [<a href="http://www.hal.t.u-tokyo.ac.jp/~inoue/pub/icassp2017/icassp2017.pdf">pdf</a>]
		</li>
                <li><span class="under">Ryosuke Furuta</span>, Ikuko Tsubaki, and Toshihiko Yamasaki<br>
                    <strong>Fast Volume Seam Carving with Multi-pass Dynamic Programming</strong><br>
                    <i>IEEE ICIP, 2016.</i> [<a href="./pub/vsc/icip2016.pdf">pdf</a>] [<a href="./pub/vsc/icip2016.mp4">video</a>]
                </li>
                <li><span class="under">Ryosuke Furuta</span>, Yusuke Fukushima, Toshihiko Yamasaki, and Kiyoharu Aizawa<br>
                    <strong>Multi-Label Classification using Class Relations Based on Higher-Order MRF Optimization</strong><br>
                    <i>IEEE CVPRW (BigVision), 2016.</i> [<a href="./pub/mrf/bigvision2016.pdf">pdf</a>]
		</li>
		<li>Toshihiko Yamasaki, Yusuke Fukushima, <span class="under">Ryosuke Furuta</span>, and Kiyoharu Aizawa<br>
                    <strong>Towards Online Prediction of Oral Presentation</strong><br>
                    <i>IEEE BigMM-ACM, 2016.</i>
		</li>
                <li>Toshihiko Yamasaki, Yusuke Fukushima, <span class="under">Ryosuke Furuta</span>, Litian Sun, Kiyoharu Aizawa, and Danushka Bollegala<br>
                    <strong>Prediction of User Ratings of Oral Presentations using Label Relations</strong><br>
                    <i>ACMMM-ASM, 2015.</i>
		</li>
		<li><span class="under">Ryosuke Furuta</span>, Satoshi Ikehata, Toshihiko Yamasaki, and Kiyoharu Aizawa<br>
                    <strong>Coarse-to-Fine Strategy for Efficient Cost-Volume Filtering</strong><br>
                    <i>IEEE ICIP, 2014.</i> (Top 10% Paper Award and IEEE SPS Japan Student Paper Award) [<a href="./pub/c2fcvf/icip2014.pdf">pdf</a>]
                </li>
            </ul>
            <h4>Domestic conferences</h4>
            <ul>
                <li> 53 papers </li>
            </ul>
            <h4>Awards</h4>
            <ul>
                <li>IIEEJ Research Encouragement Award, 2020. (co-author)</li>
                <li>IEEE Signal Processing Society (SPS) Japan Young Author Best Paper Award, 2020.</li>
                <li>IE Special Award, Technical Committee on Image Engineering, Institute of Electronics, Information and Communication Engineers, 2018.</li>
                <li>IE Award, Technical Committee on Image Engineering, Institute of Electronics, Information and Communication Engineers, 2018.</li>
                <li>Telecom System Technology Award, The Telecommunications Advancement Foundation, 2018.</li>
                <li>IE Award, Technical Committee on Image Engineering, Institute of Electronics, Information and Communication Engineers, 2015.</li>
                <li>IMPS Best and Frontier Paper Award, 2015. (co-author)</li>
                <li>IEEE Signal Processing Society (SPS) Japan Student Conference Paper Award, 2015.</li>
		<li>Harashima Hiroshi Science Award, Association for Promotion of Electrical, Electronic and Information Engineering, 2015.</li>
		<li>Top 10% Paper Award in IEEE International Conference on Image Processing (ICIP) 2014.</li>
		<li>ITE Outstanding Student Release Award, The Institute of Image Information and Television Engineers, 2013.</li>
		<li>ITE Suzuki Memorial Young Researcher's Award, The Institute of Image Information and Television Engineers, 2013.</li>
            </ul>
	    <h4>Invited Talks</h4>
	    <ul>
	      <li><strong>Fast Image Processing with Multi-pass Dynamic Programming</strong><br>
		<i>Image Processing Tokyo</i>, Tokyo Institute of Technology, Jan. 2017.</li>
	    </ul>

            <h3 id="others">Funding sources</h3>
            <ul>
                <li>Grant-in-Aid for Early-Career Scientists, Japan Society for the Promotion of Science (JSPS). (FY2021 - FY2022)</li>
                <li>Grant-in-Aid for Research activity start-up, Japan Society for the Promotion of Science (JSPS). (FY2019 - FY2020)</li>
                <li>Research fellowship for young scientists (DC1), Japan Society for the Promotion of Science (JSPS). (FY2016 - FY2018)</li>
		<li>ITE Financial Support to International Conference Student Release, The Institute of Image Information and Television Engineers, 2014. </li>
            </ul>

            <h3 id="link">Links</h3>      
            <dl>
                <dt><a href="https://www.ut-vision.org/">Sato/Sugano Laboratory</a></dt>
                <dt><a href="https://www.iis.u-tokyo.ac.jp/en/">Institute of Industrial Science, The University of Tokyo</a></dt><br>

                <dt><a href="https://www.rs.tus.ac.jp/vml/">Taniguchi Laboratory</a></dt>
                <dt><a href="https://www.tus.ac.jp/en/">Tokyo University of Science</a></dt><br>

                <dt><a href="https://www.hal.t.u-tokyo.ac.jp/lab/en?lang=en">Aizawa Yamasaki Laboratory</a></dt>
                <dt><a href="http://www.i.u-tokyo.ac.jp/index_e.shtml">Graduate School of Information Science and Technology</a></dt>	
                <dt><a href="http://www.u-tokyo.ac.jp/en/">The University of Tokyo</a></dt>
            </dl>

            <hr>
            <footer>
                <p>© Ryosuke Furuta 2021</p>
            </footer>
        </div><!-- container-narrow -->
        <script src="./furuta_files/bootstrap.js"></script>
    


</body></html>
